import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import PolynomialFeatures

from sklearn.model_selection import train_test_split

from sklearn.linear_model import LinearRegression

from sklearn import metrics

from joblib import dump, load


import pandas as pd
from google.colab import files
uploaded = files.upload()
file_name = next(iter(uploaded))
data = pd.read_excel(file_name)
columns = data.columns.tolist()


print("–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫ –¥–∞—Ç–∞—Å–µ—Ç–∞:")
display(data.head())


print("–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞ (—Å—Ç—Ä–æ–∫–∏, —Å—Ç–æ–ª–±—Ü—ã):", data.shape)

data = pd.read_excel(file_name)
data.info()

sns.set(style="ticks", font_scale=1.1)
plt.figure(figsize=(12, 10))
sns.pairplot(data, diag_kind='kde', corner=False, plot_kws={'alpha': 0.6})
plt.suptitle("–ú–∞—Ç—Ä–∏—Ü–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π –∏ scatter-plot –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤", y=1.02)
plt.show()

numeric_data = data.select_dtypes(include=['int64', 'float64'])
correlation_matrix = numeric_data.corr()

print("–ú–∞—Ç—Ä–∏—Ü–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π (—Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã):")
display(correlation_matrix)

plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt=".02f")
plt.title("–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É —á–∏—Å–ª–æ–≤—ã–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏")
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(14, 10))

plt.subplot(2, 2, 1)
plt.hist(data['–¶–µ–Ω–∞ –∫–≤ –º'].dropna(), bins=30, color='royalblue', alpha=0.7, edgecolor='black')
plt.xlabel('–¶–µ–Ω–∞ –∑–∞ –∫–≤.–º (—Ä—É–±)')
plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–≤–∞—Ä—Ç–∏—Ä')
plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–Ω –∑–∞ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–π –º–µ—Ç—Ä')
plt.grid(True, linestyle='--', alpha=0.3)

plt.subplot(2, 2, 2)
plt.scatter(data['–ü–ª–æ—â–∞–¥—å'], data['–¶–µ–Ω–∞ –∫–≤ –º'], color='forestgreen', alpha=0.5)
plt.xlabel('–ü–ª–æ—â–∞–¥—å –∫–≤–∞—Ä—Ç–∏—Ä—ã (–∫–≤.–º)')
plt.ylabel('–¶–µ–Ω–∞ –∑–∞ –∫–≤.–º (—Ä—É–±)')
plt.title('–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å —Ü–µ–Ω—ã –æ—Ç –ø–ª–æ—â–∞–¥–∏')
plt.grid(True, linestyle='--', alpha=0.3)

plt.subplot(2, 2, 3)
data.boxplot(column='–¶–µ–Ω–∞ –∫–≤ –º', by='–ö–ª–∞—Å—Å –ö....', ax=plt.gca())
plt.xlabel('–ö–ª–∞—Å—Å –∂–∏–ª—å—è')
plt.ylabel('–¶–µ–Ω–∞ –∑–∞ –∫–≤.–º (—Ä—É–±)')
plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–Ω –ø–æ –∫–ª–∞—Å—Å–∞–º')
plt.suptitle('')
plt.grid(True, linestyle='--', alpha=0.3)
plt.xticks(rotation=45)


plt.subplot(2, 2, 4)
plt.scatter(data['–≠—Ç–∞–∂'], data['–¶–µ–Ω–∞ –∫–≤ –º'], color='darkorange', alpha=0.5)
plt.xlabel('–≠—Ç–∞–∂')
plt.ylabel('–¶–µ–Ω–∞ –∑–∞ –∫–≤.–º (—Ä—É–±)')
plt.title('–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å —Ü–µ–Ω—ã –æ—Ç —ç—Ç–∞–∂–∞')
plt.grid(True, linestyle='--', alpha=0.3)

plt.tight_layout(pad=3.0)
plt.show()

X = data.drop('–ü–ª–æ—â–∞–¥—å', axis=1)
y = data['–¶–µ–Ω–∞ –∫–≤ –º']

print("\n–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫ X:")
print(X.head())

print("\n–ü–µ—Ä–≤—ã–µ 5 –∑–Ω–∞—á–µ–Ω–∏–π y:")
print(y.head())

from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns
categorical_cols = X.select_dtypes(include=['object']).columns
from sklearn.preprocessing import StandardScaler, PolynomialFeatures


numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_cols),
        ('cat', categorical_transformer, categorical_cols)
    ])

full_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('poly', PolynomialFeatures(degree=2, include_bias=False))
])

poly_features = full_pipeline.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(
    poly_features,
    y,
    test_size=0.3,
    random_state=101
)

print("–†–∞–∑–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö:")
print(f"–û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_train.shape}")
print(f"–¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_test.shape}")

from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import Pipeline

polymodel = LinearRegression()
polymodel.fit(X_train, y_train)

y_pred = polymodel.predict(X_test)

print("=== –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏ ===")
print(f"R¬≤ Score: {r2_score(y_test, y_pred):.4f}")
print(f"MAE: {mean_absolute_error(y_test, y_pred):.4f}")
print(f"MSE: {mean_squared_error(y_test, y_pred):.4f}")
print(f"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}")

try:
    if 'full_pipeline' in globals():
        poly_feature_names = full_pipeline.named_steps['poly'].get_feature_names_out(
            input_features=full_pipeline.named_steps['preprocessor'].get_feature_names_out()
        )

        coef_df = pd.DataFrame({
            'Feature': poly_feature_names,
            'Coefficient': polymodel.coef_
        }).sort_values('Coefficient', key=abs, ascending=False)

        print("\n–¢–æ–ø-10 –≤–∞–∂–Ω–µ–π—à–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
        print(coef_df.head(10))
    else:
        print("\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è: full_pipeline –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω, –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

except Exception as e:
    print("\n–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:", str(e))
    print("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤:", len(polymodel.coef_))

plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title(f'Actual vs Predicted (R¬≤={r2_score(y_test, y_pred):.2f})')
plt.show()

results_df = pd.DataFrame({
    'Actual': y_test.values,
    'Predicted': y_pred,
    'Residual': y_test.values - y_pred
}).round(2)

print("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏:")
display(results_df.head())

print("\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤:")
print(results_df['Residual'].describe())

plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
sns.histplot(results_df['Residual'], kde=True, bins=20)
plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Å—Ç–∞—Ç–∫–æ–≤')
plt.axvline(0, color='r', linestyle='--')

plt.subplot(1, 2, 2)
sns.scatterplot(x='Predicted', y='Residual', data=results_df, alpha=0.5)
plt.axhline(0, color='r', linestyle='--')
plt.title('–û—Å—Ç–∞—Ç–∫–∏ vs –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è')

plt.tight_layout()
plt.show()

print("\n–¢–æ–ø-5 –ª—É—á—à–∏—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π:")
display(results_df.sort_values('Residual', key=abs).head())

print("\n–¢–æ–ø-5 —Ö—É–¥—à–∏—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π:")
display(results_df.sort_values('Residual', key=abs, ascending=False).head())

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import metrics

metrics_dict = {
    'MAE': metrics.mean_absolute_error(y_test, y_pred),
    'MSE': metrics.mean_squared_error(y_test, y_pred),
    'RMSE': np.sqrt(metrics.mean_squared_error(y_test, y_pred)),
    'R2': metrics.r2_score(y_test, y_pred),
    'Median AE': metrics.median_absolute_error(y_test, y_pred),
    'Max Error': metrics.max_error(y_test, y_pred)
}

metrics_df = pd.DataFrame.from_dict(metrics_dict,
                                  orient='index',
                                  columns=['Value']).round(3)

error_metrics = metrics_df.drop('R2')
max_metric = error_metrics.loc[error_metrics['Value'].idxmax()]

plt.figure(figsize=(12, 6))
ax = sns.barplot(x=metrics_df.index, y='Value',
                data=metrics_df.reset_index(),
                palette=['red' if x == max_metric.name else 'blue' for x in metrics_df.index])
plt.title('–ú–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏', fontsize=14)
plt.ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏')
plt.xticks(rotation=45)

max_value = max_metric['Value']
max_index = list(metrics_df.index).index(max_metric.name)
ax.annotate(f'Max: {max_value:.3f}',
           xy=(max_index, max_value),
           xytext=(max_index, max_value + 0.1*max_value),
           ha='center',
           arrowprops=dict(facecolor='black', shrink=0.05))

for i, v in enumerate(metrics_df['Value']):
    plt.text(i, v+0.01, str(v), ha='center')
plt.show()

print("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏:")
display(metrics_df)

print(f"\n–°–∞–º—ã–π –≤—ã—Å–æ–∫–∏–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –æ—à–∏–±–∫–∏: {max_metric.name} = {max_value:.3f}")
if max_metric.name == 'MSE':
    print("–ú–µ—Ç—Ä–∏–∫–∞ MSE —è–≤–ª—è–µ—Ç—Å—è —Å–∞–º–æ–π –≤—ã—Å–æ–∫–æ–π —Å—Ä–µ–¥–∏ –æ—à–∏–±–æ–∫")
    print("–≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –º–æ–¥–µ–ª—å –∏–º–µ–µ—Ç –Ω–∞–∏–±–æ–ª—å—à–∏–µ –∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω—ã–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è")
    print("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
    print("- –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤ –≤ –¥–∞–Ω–Ω—ã—Ö")
    print("- –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –¥—Ä—É–≥–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã (Random Forest, Gradient Boosting)")
    print("- –î–æ–±–∞–≤–∏—Ç—å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é –≤ –º–æ–¥–µ–ª—å")

residuals = y_test - y_pred
print("\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤:")
display(pd.DataFrame(residuals.describe()).transpose())

plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
sns.histplot(residuals, kde=True, bins=30)
plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫')
plt.axvline(0, color='r', linestyle='--')

plt.subplot(1, 2, 2)
sns.scatterplot(x=y_pred, y=residuals, alpha=0.5)
plt.axhline(0, color='r', linestyle='--')
plt.xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è')
plt.ylabel('–û—à–∏–±–∫–∏')
plt.title('–î–∏–∞–≥—Ä–∞–º–º–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤')

plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
from scipy.sparse import issparse
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline

X = pd.DataFrame({
    'numeric1': [1, 2, 3, np.nan, 5, 6],
    'numeric2': [1.1, 2.2, 3.3, 4.4, 5.5, 6.6],
    'categorical': ['A', 'B', 'A', 'C', 'B', 'A']
})

numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))  # sparse_output=False –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –º–∞—Å—Å–∏–≤–∞
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, ['numeric1', 'numeric2']),
        ('cat', categorical_transformer, ['categorical'])
    ]
)

X_processed = preprocessor.fit_transform(X)

print(f"–¢–∏–ø X_processed: {type(X_processed)}")

if issparse(X_processed):
    print("\n–†–∞–∑—Ä–µ–∂–µ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ (sparse matrix) - –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π:")
    X_dense = X_processed.toarray()
    print(f"–í—Å–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {X_dense.size}")
    print(f"–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π (NaN): {np.isnan(X_dense).sum()}")
    print(f"–ù—É–ª–µ–≤—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {np.sum(X_dense == 0)}")
else:
    print("\n–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ –º–∞—Å—Å–∏–≤–µ:")
    print(f"–í—Å–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {X_processed.size}")
    print(f"–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π (NaN): {np.isnan(X_processed).sum()}")
    print(f"–ë–µ—Å–∫–æ–Ω–µ—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π (inf): {np.isinf(X_processed).sum()}")

print("\n–§–æ—Ä–º–∞ –¥–∞–Ω–Ω—ã—Ö:", X_processed.shape)
print("–¢–∏–ø –¥–∞–Ω–Ω—ã—Ö –≤ –º–∞—Å—Å–∏–≤–µ:", X_processed.dtype)

print("\n–ü—Ä–∏–º–µ—Ä –ø–µ—Ä–≤—ã—Ö 5 —Å—Ç—Ä–æ–∫:")
print(X_processed[:5])

print(f"\n–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {np.min(X_processed)}")
print(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {np.max(X_processed)}")
print(f"–°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {np.mean(X_processed):.3f}")
print(f"–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {np.std(X_processed):.3f}")

try:
    feature_names = preprocessor.get_feature_names_out()
    X_df = pd.DataFrame(X_processed, columns=feature_names)
    print(f"\n–ò–º–µ–Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {feature_names}")
    print("\n–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫ –≤ DataFrame:")
    display(X_df.head())
except:
    print("\n–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–º–µ–Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

try:
    X_processed = X.select_dtypes(include=['int64', 'float64']).copy()

    threshold = len(X_processed) * 0.7
    X_processed = X_processed.dropna(axis=1, thresh=threshold)

    X_processed = X_processed.dropna()
    y_processed = y.loc[X_processed.index]

except Exception as e:
    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
    raise

print("\n–ü–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
print(f"–§–æ—Ä–º–∞ X: {X_processed.shape}")
print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–æ–ª–±—Ü–æ–≤: {len(X_processed.columns)}")
print("\n–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫:")
display(X_processed.head())

try:
    X_train, X_test, y_train, y_test = train_test_split(
        X_processed, y_processed,
        test_size=0.3,
        random_state=101
    )

    print(f"\n–†–∞–∑–º–µ—Ä —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞: {X_train.shape}")
    print(f"–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –Ω–∞–±–æ—Ä–∞: {X_test.shape}")

except Exception as e:
    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
    raise

try:
    model = LinearRegression()
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)

    print("\n–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏:")
    print(f"R2 Score: {r2_score(y_test, y_pred):.4f}")
    print(f"MSE: {mean_squared_error(y_test, y_pred):.4f}")
    print(f"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}")

except Exception as e:
    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏: {str(e)}")
    raise

if len(X_processed.columns) <= 20:
    coef_df = pd.DataFrame({
        'Feature': X_processed.columns,
        'Coefficient': model.coef_
    }).sort_values('Coefficient', key=abs, ascending=False)

    print("\n–í–∞–∂–Ω–µ–π—à–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:")
    display(coef_df.head(10))
else:
    print(f"\n–ü—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ ({len(X_processed.columns)}), –∞–Ω–∞–ª–∏–∑ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤ –Ω–µ –≤—ã–≤–æ–¥–∏—Ç—Å—è")

import warnings
warnings.filterwarnings("ignore", message="Thread 'MainThread': missing ScriptRunContext!")
warnings.filterwarnings("ignore", message="No runtime found, using MemoryCacheStorageManager")

import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
import requests
from io import BytesIO
import tempfile
import os
import base64
from pptx import Presentation
from pptx.util import Inches
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_squared_error, r2_score

st.set_page_config(
    page_title="–ê–Ω–∞–ª–∏–∑ —Ä—ã–Ω–∫–∞ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏",
    page_icon="üè†",
    layout="wide",
    initial_sidebar_state="expanded"
)

@st.cache_data
def load_data_from_github():
    github_url = "https://github.com/evoluteorburn-lab/HSE_exam_DS16_GusevA/raw/357f3cc05db797cb365a5bd408e5d4784d69ed96/Cian.xlsx"

    try:
        st.info("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å GitHub...")
        response = requests.get(github_url)
        response.raise_for_status()

        df = pd.read_excel(BytesIO(response.content))
        st.success(f"–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. –†–∞–∑–º–µ—Ä —Ç–∞–±–ª–∏—Ü—ã: {df.shape}")
        return df

    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö: {e}")
        st.info("–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ...")
        return create_demo_data()

def create_demo_data():
    data = {
        'ID –ö–æ—Ä–ø—É—Å–∞': [1, 2, 3, 4, 5],
        'ID –ñ–ö': [101, 101, 102, 103, 103],
        '–ñ–ö —Ä—É—Å': ['–ñ–ö –ê', '–ñ–ö –ê', '–ñ–ö –ë', '–ñ–ö –í', '–ñ–ö –í'],
        '–ñ–ö –∞–Ω–≥–ª': [None, None, None, None, None],
        '–ö–æ—Ä–ø—É—Å': ['–ö–æ—Ä–ø—É—Å 1', '–ö–æ—Ä–ø—É—Å 2', '–ö–æ—Ä–ø—É—Å 1', '–ö–æ—Ä–ø—É—Å 1', '–ö–æ—Ä–ø—É—Å 2'],
        '–∫—Ä –ö–æ—Ä–ø—É—Å': ['–ö–æ—Ä–ø. 1', '–ö–æ—Ä–ø. 2', '–ö–æ—Ä–ø. 1', '–ö–æ—Ä–ø. 1', '–ö–æ—Ä–ø. 2'],
        '–†–µ–≥–∏–æ–Ω': ['–ú–æ—Å–∫–≤–∞', '–ú–æ—Å–∫–≤–∞', '–°–ü–±', '–ú–æ—Å–∫–≤–∞', '–°–ü–±'],
        '–ú–µ—Ç—Ä–æ': ['–ú–µ—Ç—Ä–æ 1', '–ú–µ—Ç—Ä–æ 2', '–ú–µ—Ç—Ä–æ 3', '–ú–µ—Ç—Ä–æ 1', '–ú–µ—Ç—Ä–æ 3'],
        'ID –∫–≤': [1001, 1002, 1003, 1004, 1005],
        '–î–∞—Ç–∞ –∞–∫—Ç—É–∞–ª–∏–∑–∞—Ü–∏–∏': [datetime.now()] * 5,
        '–ö–æ–º–Ω–∞—Ç': [1, 2, 3, 1, 2],
        '–ü–ª–æ—â–∞–¥—å': [30.5, 45.2, 60.1, 25.0, 40.0],
        '–¶–µ–Ω–∞': [5000000, 8000000, 12000000, 4000000, 7000000],
        '–¶–µ–Ω–∞ –∫–≤ –º': [int(5000000/30.5), int(8000000/45.2), int(12000000/60.1), int(4000000/25.0), int(7000000/40.0)],
        '–≠—Ç–∞–∂': [5, 8, 3, 2, 7],
        '–ù–æ–º–µ—Ä –Ω–∞ —ç—Ç–∞–∂–µ': [1, 2, 3, 1, 2],
        '–ù–æ–º–µ—Ä –≤ –∫–æ—Ä–ø—É—Å–µ': ['–ê1', '–ë2', '–í3', '–ì4', '–î5'],
        '–ù–æ–º–µ—Ä —Å–µ–∫—Ü–∏–∏': [1, 1, 2, 1, 2],
        '–ê–¥—Ä–µ—Å –∫–æ—Ä–ø': ['–ê–¥—Ä–µ—Å 1', '–ê–¥—Ä–µ—Å 2', '–ê–¥—Ä–µ—Å 3', '–ê–¥—Ä–µ—Å 4', '–ê–¥—Ä–µ—Å 5'],
        'lat': [55.75, 55.78, 59.93, 55.75, 59.93],
        'lng': [37.61, 37.65, 30.32, 37.61, 30.32],
        '–†–∞–π–æ–Ω –ì–æ—Ä–æ–¥': ['–¶–ê–û', '–°–ê–û', '–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π', '–¶–ê–û', '–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π'],
        '–û–∫—Ä—É–≥ –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ': ['–û–∫—Ä—É–≥ 1', '–û–∫—Ä—É–≥ 2', '–û–∫—Ä—É–≥ 3', '–û–∫—Ä—É–≥ 1', '–û–∫—Ä—É–≥ 3'],
        '–ê–¢–î': ['–ê–¢–î 1', '–ê–¢–î 2', '–ê–¢–î 3', '–ê–¢–î 1', '–ê–¢–î 3'],
        '–ò—Å—Ç–æ—á–Ω–∏–∫': ['–¶–ò–ê–ù'] * 5,
        '–¢–∏–ø –∫–æ—Ä–ø—É—Å–∞': ['–ú–æ–Ω–æ–ª–∏—Ç', '–ü–∞–Ω–µ–ª—å', '–ö–∏—Ä–ø–∏—á', '–ú–æ–Ω–æ–ª–∏—Ç', '–ü–∞–Ω–µ–ª—å'],
        '–ö–ª–∞—Å—Å –ö....': ['–ö–æ–º—Ñ–æ—Ä—Ç', '–ë–∏–∑–Ω–µ—Å', '–ü—Ä–µ–º–∏—É–º', '–≠–∫–æ–Ω–æ–º', '–ö–æ–º—Ñ–æ—Ä—Ç'],
        '–¢–∏–ø –∫–≤/–∞–ø': ['–ö–≤–∞—Ä—Ç–∏—Ä–∞', '–ö–≤–∞—Ä—Ç–∏—Ä–∞', '–ê–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç—ã', '–ö–≤–∞—Ä—Ç–∏—Ä–∞', '–ê–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç—ã'],
        '–ó–∞—Å—Ç—Ä–æ–π—â–∏–∫': ['–ü–ò–ö', '–°–∞–º–æ–ª–µ—Ç', '–≠—Ç–∞–ª–æ–Ω', '–ü–ò–ö', '–°–∞–º–æ–ª–µ—Ç'],
        '–¢–∏–ø –ø–æ–º–µ—â–µ–Ω–∏—è': ['–ö–≤–∞—Ä—Ç–∏—Ä–∞', '–ö–≤–∞—Ä—Ç–∏—Ä–∞', '–ê–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç—ã', '–ö–≤–∞—Ä—Ç–∏—Ä–∞', '–ê–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç—ã'],
        '–û—Ç–¥–µ–ª–∫–∞ –ø–æ–º–µ—â–µ–Ω–∏—è': ['–î–∞', '–ù–µ—Ç', '–î–∞', '–ù–µ—Ç', '–î–∞'],
        '–û—Ç–¥–µ–ª–∫–∞ –ö': ['–î–∞', '–ù–µ—Ç', '–î–∞', '–ù–µ—Ç', '–î–∞'],
        '–î–æ–≥–æ–≤–æ—Ä –ö': ['–î–î–£', '–≠—Å–∫—Ä–æ—É', '–î–î–£', '–≠—Å–∫—Ä–æ—É', '–î–î–£'],
        '–°–¥–∞—á–∞ –ö': ['2024', '2025', '2024', '2025', '2024'],
        '–¶–µ–Ω–∞ —Å–æ —Å–∫–∏–¥–∫–æ–π': [0, 0, 0, 0, 0],
        '–ó–æ–Ω–∞': ['–í –ø—Ä–µ–¥–µ–ª–∞—Ö –¢–¢–ö', '–ó–∞ –ú–ö–ê–î', '–í –ø—Ä–µ–¥–µ–ª–∞—Ö –ö–ê–î', '–í –ø—Ä–µ–¥–µ–ª–∞—Ö –¢–¢–ö', '–í –ø—Ä–µ–¥–µ–ª–∞—Ö –ö–ê–î'],
        '–û—Ç–¥–µ–ª–∫–∞ —Ç–µ–∫—Å—Ç': [None] * 5,
        '–°—Ç–∞—Ä—Ç –ø—Ä–æ–¥–∞–∂ –ö': [2022.0, 2023.0, 2021.0, 2022.0, 2023.0],
        '–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ–Ω—ã –ø–æ—Å–ª–µ–¥–Ω–µ–µ': [0, 0, 0, 0, 0],
        '–≠–∫—Å–ø–æ–∑–∏—Ü–∏—è': [10, 15, 20, 5, 12],
        '–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ–Ω—ã': [100000, 50000, 200000, 10000, 80000]
    }
    return pd.DataFrame(data)


def fit_polynomial_regression(df, x_col, y_col, degree=2, test_size=0.2, random_state=42):

    if x_col not in df.columns or y_col not in df.columns:
        raise ValueError(f"–ö–æ–ª–æ–Ω–∫–∏ {x_col} –∏–ª–∏ {y_col} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –¥–∞–Ω–Ω—ã—Ö")

    data_clean = df[[x_col, y_col]].dropna()
    if len(data_clean) == 0:
        raise ValueError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –ø—Ä–æ–ø—É—Å–∫–æ–≤")

    X = data_clean[[x_col]].values
    y = data_clean[y_col].values

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state
    )


    model = make_pipeline(
        PolynomialFeatures(degree, include_bias=False),
        LinearRegression()
    )
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(mse)


    lin_reg = model.named_steps['linearregression']
    poly_features = model.named_steps['polynomialfeatures']


    feature_names = poly_features.get_feature_names_out([x_col])
    coeffs = np.concatenate(([lin_reg.intercept_], lin_reg.coef_))

    return model, mse, rmse, r2, coeffs, feature_names

df = load_data_from_github()

if '–ü–ª–æ—â–∞–¥—å' in df.columns:
    df['–ü–ª–æ—â–∞–¥—å'] = df['–ü–ª–æ—â–∞–¥—å'].fillna(df['–ü–ª–æ—â–∞–¥—å'].median())
if '–ö–æ–º–Ω–∞—Ç' in df.columns:
    df['–ö–æ–º–Ω–∞—Ç'] = df['–ö–æ–º–Ω–∞—Ç'].fillna(df['–ö–æ–º–Ω–∞—Ç'].mode()[0] if not df['–ö–æ–º–Ω–∞—Ç'].mode().empty else 2)
if '–≠—Ç–∞–∂' in df.columns:
    df['–≠—Ç–∞–∂'] = df['–≠—Ç–∞–∂'].fillna(df['–≠—Ç–∞–∂'].median())

HAPPY_PEOPLE_IMAGES = [
    "https://t4.ftcdn.net/jpg/04/28/56/41/360_F_428564146_9As0qycLqkWfqycqFgD12pWnXeoxngem.jpg",
    "https://avatars.mds.yandex.net/i?id=679b6d004b22fe95070e15979eb9e51a_l-16493803-images-thumbs&n=13"
]

def download_image(url):
    try:
        response = requests.get(url)
        response.raise_for_status()
        return response.content
    except:
        return None

def create_presentation(input_data, filtered_df):
    prs = Presentation()

    price_column = '–¶–µ–Ω–∞ –∫–≤ –º' if '–¶–µ–Ω–∞ –∫–≤ –º' in filtered_df.columns else '–¶–µ–Ω–∞'
    if price_column in filtered_df.columns:
        avg_price = filtered_df[price_column].mean()
        median_price = filtered_df[price_column].median()
    else:
        avg_price = median_price = 0

    count = len(filtered_df)

    slide_layout = prs.slide_layouts[0]
    slide = prs.slides.add_slide(slide_layout)
    title = slide.shapes.title
    subtitle = slide.placeholders[1]

    title.text = "–ö–æ–º–º–µ—Ä—á–µ—Å–∫–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ"
    subtitle.text = f"–ê–Ω–∞–ª–∏–∑ —Ä—ã–Ω–∫–∞ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏\n{datetime.now().strftime('%d.%m.%Y')}"

    slide_layout = prs.slide_layouts[1]
    slide = prs.slides.add_slide(slide_layout)
    title = slide.shapes.title
    title.text = "–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞"

    content = slide.placeholders[1]
    tf = content.text_frame
    tf.text = ""

    for key, value in input_data.items():
        if value is not None:
            if key == '–ö–ª–∞—Å—Å –ö....':
                p = tf.add_paragraph()
                p.text = f"–ö–ª–∞—Å—Å –∫–≤–∞—Ä—Ç–∏—Ä—ã: {value}"
            elif key == '–ü–ª–æ—â–∞–¥—å –æ—Ç' and input_data.get('–ü–ª–æ—â–∞–¥—å –¥–æ'):
                p = tf.add_paragraph()
                p.text = f"–ü–ª–æ—â–∞–¥—å: –æ—Ç {input_data['–ü–ª–æ—â–∞–¥—å –æ—Ç']} –¥–æ {input_data['–ü–ª–æ—â–∞–¥—å –¥–æ']} –º¬≤"
            elif key not in ['–ü–ª–æ—â–∞–¥—å –æ—Ç', '–ü–ª–æ—â–∞–¥—å –¥–æ']:
                p = tf.add_paragraph()
                p.text = f"{key}: {value}"

    slide_layout = prs.slide_layouts[1]
    slide = prs.slides.add_slide(slide_layout)
    title = slide.shapes.title
    title.text = "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞"

    content = slide.placeholders[1]
    tf = content.text_frame
    tf.text = ""

    p = tf.add_paragraph()
    p.text = f"–ù–∞–π–¥–µ–Ω–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤: {count}"
    p = tf.add_paragraph()
    p.text = f"–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞ –∑–∞ –º¬≤: {avg_price:,.0f} —Ä—É–±."
    p = tf.add_paragraph()
    p.text = f"–ú–µ–¥–∏–∞–Ω–Ω–∞—è —Ü–µ–Ω–∞ –∑–∞ –º¬≤: {median_price:,.0f} —Ä—É–±."

    slide_layout = prs.slide_layouts[1]
    slide = prs.slides.add_slide(slide_layout)
    title = slide.shapes.title
    title.text = "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∏ –∫–æ–Ω—Ç–∞–∫—Ç—ã"

    content = slide.placeholders[1]
    tf = content.text_frame
    tf.text = ""

    p = tf.add_paragraph()
    p.text = "–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –≤–∞—à–∏–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º"
    p = tf.add_paragraph()
    p.text = "–ú–µ–Ω–µ–¥–∂–µ—Ä: –ì—É—Å–µ–≤ –ê–ª–µ–∫—Å–∞–Ω–¥—Ä –°–µ—Ä–≥–µ–µ–≤–∏—á"
    p = tf.add_paragraph()
    p.text = "–¢–µ–ª–µ—Ñ–æ–Ω: +7 (977) 123-45-67"
    p = tf.add_paragraph()
    p.text = "Email: gusev@realestate.ru"

    with tempfile.NamedTemporaryFile(delete=False, suffix='.pptx') as tmp:
        prs.save(tmp.name)
        with open(tmp.name, 'rb') as f:
            pptx_bytes = f.read()
    os.unlink(tmp.name)

    return pptx_bytes

def get_download_link(file_bytes, filename, text):
    b64 = base64.b64encode(file_bytes).decode()
    return f'<a href="data:application/octet-stream;base64,{b64}" download="{filename}">{text}</a>'

st.title("–ê–Ω–∞–ª–∏–∑ —Ä—ã–Ω–∫–∞ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏")
st.markdown("### –í–≤–µ–¥–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–≤–∞—Ä—Ç–∏—Ä—ã –¥–ª—è –ø–æ–∏—Å–∫–∞")

with st.sidebar:
    st.header("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö")
    st.write(f"**–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞:** {df.shape[0]} –∑–∞–ø–∏—Å–µ–π, {df.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

    if '–ö–ª–∞—Å—Å –ö....' in df.columns:
        unique_classes = [str(x) for x in df['–ö–ª–∞—Å—Å –ö....'].unique() if pd.notna(x)]
        st.write(f"**–ö–ª–∞—Å—Å—ã –∫–≤–∞—Ä—Ç–∏—Ä:** {', '.join(unique_classes)}")

    if st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å –ø–µ—Ä–≤—ã–µ 5 –∑–∞–ø–∏—Å–µ–π"):
        st.dataframe(df.head())

    if st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"):
        st.write(df.describe())

    st.header("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏")
    reg_degree = st.slider("–°—Ç–µ–ø–µ–Ω—å –ø–æ–ª–∏–Ω–æ–º–∞", 1, 5, 2)
    reg_test_size = st.slider("–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏", 0.1, 0.5, 0.2)

col1, col2 = st.columns(2)

with col1:
    st.subheader("–û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã")

    def get_unique_values(column_name, default_options=None):
        if column_name in df.columns and not df[column_name].empty:
            unique_vals = df[column_name].dropna().unique().tolist()
            return sorted([x for x in unique_vals if x is not None and x != ''])
        return default_options if default_options else []

    class_options = get_unique_values('–ö–ª–∞—Å—Å –ö....', ['–≠–∫–æ–Ω–æ–º', '–ö–æ–º—Ñ–æ—Ä—Ç', '–ë–∏–∑–Ω–µ—Å', '–ü—Ä–µ–º–∏—É–º'])
    class_input = st.selectbox('–ö–ª–∞—Å—Å –∫–≤–∞—Ä—Ç–∏—Ä—ã', options=[None] + class_options)

    area_min = st.number_input('–ü–ª–æ—â–∞–¥—å –æ—Ç (–º¬≤)', min_value=0.0, value=0.0)
    area_max = st.number_input('–ü–ª–æ—â–∞–¥—å –¥–æ (–º¬≤)', min_value=0.0, value=0.0)

with col2:
    st.subheader("–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã")

    rooms_options = get_unique_values('–ö–æ–º–Ω–∞—Ç', [1, 2, 3, 4, 5])
    rooms_input = st.selectbox('–ö–æ–º–Ω–∞—Ç', options=[None] + rooms_options)

    floor_input = st.number_input('–≠—Ç–∞–∂', min_value=0, value=0)

    district_options = get_unique_values('–†–∞–π–æ–Ω –ì–æ—Ä–æ–¥', ['–¶–ê–û', '–°–ê–û', '–Æ–ê–û'])
    district_input = st.selectbox('–†–∞–π–æ–Ω', options=[None] + district_options)

    type_options = get_unique_values('–¢–∏–ø –ø–æ–º–µ—â–µ–Ω–∏—è', ['–ö–≤–∞—Ä—Ç–∏—Ä–∞', '–ê–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç—ã'])
    type_input = st.selectbox('–¢–∏–ø', options=[None] + type_options)

    builder_options = get_unique_values('–ó–∞—Å—Ç—Ä–æ–π—â–∏–∫', ['–ü–ò–ö', '–°–∞–º–æ–ª–µ—Ç', '–≠—Ç–∞–ª–æ–Ω'])
    builder_input = st.selectbox('–ó–∞—Å—Ç—Ä–æ–π—â–∏–∫', options=[None] + builder_options)

    finish_options = get_unique_values('–û—Ç–¥–µ–ª–∫–∞ –ø–æ–º–µ—â–µ–Ω–∏—è', ['–î–∞', '–ù–µ—Ç'])
    finish_input = st.selectbox('–û—Ç–¥–µ–ª–∫–∞', options=[None] + finish_options)

st.subheader("–ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞")

infra_cols = st.columns(5)
infrastructure_options = {}

infrastructure_columns = [
    '–®–∫–æ–ª–∞/–î–µ—Ç—Å–∫–∏–π –°–∞–¥', '–ü–∞—Ä–∫/–ó–æ–Ω–∞ –æ—Ç–¥—ã—Ö–∞', '–°–ø–æ—Ä—Ç', '–ü–∞—Ä–∫–æ–≤–∫–∞', '–†–µ—Å—Ç–æ—Ä–∞–Ω—ã'
]

for i, col_name in enumerate(infrastructure_columns):
    if col_name in df.columns:
        options = get_unique_values(col_name, [])
        with infra_cols[i]:
            infrastructure_options[col_name] = st.selectbox(
                col_name,
                options=[None] + options,
                key=f"infra_{col_name}"
            )

col3, col4 = st.columns(2)
with col3:
    confirm_kp = st.checkbox('–ü–æ–ª—É—á–∏—Ç—å –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ', value=False)
with col4:
    export_pptx = st.checkbox('–í—ã–≥—Ä—É–∑–∏—Ç—å –≤ PPTX', value=False)
    show_regression = st.checkbox('–ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑', value=False)
    show_infrastructure = st.checkbox('–ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—É', value=True)

if st.button('–°—Ä–∞–≤–Ω–∏—Ç—å —Ü–µ–Ω—É', type='primary'):
    input_data = {
        '–ö–ª–∞—Å—Å –ö....': class_input,
        '–ü–ª–æ—â–∞–¥—å –æ—Ç': area_min if area_min > 0 else None,
        '–ü–ª–æ—â–∞–¥—å –¥–æ': area_max if area_max > 0 else None,
        '–ö–æ–º–Ω–∞—Ç': rooms_input,
        '–≠—Ç–∞–∂': floor_input if floor_input > 0 else None,
        '–†–∞–π–æ–Ω –ì–æ—Ä–æ–¥': district_input,
        '–¢–∏–ø –ø–æ–º–µ—â–µ–Ω–∏—è': type_input,
        '–ó–∞—Å—Ç—Ä–æ–π—â–∏–∫': builder_input,
        '–û—Ç–¥–µ–ª–∫–∞ –ø–æ–º–µ—â–µ–Ω–∏—è': finish_input
    }

    for col_name, value in infrastructure_options.items():
        input_data[col_name] = value

    filtered_df = df.copy()

    for key, value in input_data.items():
        if value is not None and key in filtered_df.columns:
            if key == '–ü–ª–æ—â–∞–¥—å –æ—Ç':
                filtered_df = filtered_df[filtered_df['–ü–ª–æ—â–∞–¥—å'] >= value]
            elif key == '–ü–ª–æ—â–∞–¥—å –¥–æ':
                filtered_df = filtered_df[filtered_df['–ü–ª–æ—â–∞–¥—å'] <= value]
            elif key in ['–ö–æ–º–Ω–∞—Ç', '–≠—Ç–∞–∂']:
                filtered_df = filtered_df[filtered_df[key] == value]
            else:
                filtered_df = filtered_df[filtered_df[key] == value]

    if len(filtered_df) == 0:
        st.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤ –ø–æ —É–∫–∞–∑–∞–Ω–Ω—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º")
        st.info("–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞")
    else:
        price_column = '–¶–µ–Ω–∞ –∫–≤ –º' if '–¶–µ–Ω–∞ –∫–≤ –º' in filtered_df.columns else '–¶–µ–Ω–∞'
        if price_column not in filtered_df.columns:
            st.error("–ö–æ–ª–æ–Ω–∫–∞ —Å —Ü–µ–Ω–æ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –¥–∞–Ω–Ω—ã—Ö!")
            st.stop()

        class_avg_price = filtered_df[price_column].mean()
        class_median_price = filtered_df[price_column].median()

        st.success("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞")

        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("–ù–∞–π–¥–µ–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤", len(filtered_df))
        with col2:
            st.metric("–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞ –∑–∞ –º¬≤", f"{class_avg_price:,.0f} —Ä—É–±.")
        with col3:
            st.metric("–ú–µ–¥–∏–∞–Ω–Ω–∞—è —Ü–µ–Ω–∞", f"{class_median_price:,.0f} —Ä—É–±.")

        fig, ax = plt.subplots(figsize=(10, 6))
        sns.histplot(filtered_df[price_column], kde=True, ax=ax)
        ax.set_xlabel('–¶–µ–Ω–∞ –∑–∞ –º¬≤ (—Ä—É–±.)')
        ax.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')
        ax.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–Ω –≤ –≤—ã–±–æ—Ä–∫–µ')
        st.pyplot(fig)

        st.subheader("–ù–∞–π–¥–µ–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã")

        display_columns = ['–ü–ª–æ—â–∞–¥—å', '–ö–æ–º–Ω–∞—Ç', '–≠—Ç–∞–∂', '–†–∞–π–æ–Ω –ì–æ—Ä–æ–¥', '–¶–µ–Ω–∞ –∫–≤ –º']
        if '–ö–ª–∞—Å—Å –ö....' in filtered_df.columns:
            display_columns.insert(0, '–ö–ª–∞—Å—Å –ö....')

        if show_infrastructure:
            for col in infrastructure_columns:
                if col in filtered_df.columns:
                    display_columns.append(col)

        st.dataframe(
            filtered_df[display_columns].rename(columns={
                '–ö–ª–∞—Å—Å –ö....': '–ö–ª–∞—Å—Å',
                '–†–∞–π–æ–Ω –ì–æ—Ä–æ–¥': '–†–∞–π–æ–Ω',
                '–¶–µ–Ω–∞ –∫–≤ –º': '–¶–µ–Ω–∞ –∑–∞ –º¬≤'
            }).style.format({
                '–¶–µ–Ω–∞ –∑–∞ –º¬≤': '{:,.0f} —Ä—É–±.',
                '–ü–ª–æ—â–∞–¥—å': '{:.1f} –º¬≤'
            }),
            height=300
        )

        if show_regression and len(filtered_df) > 10:
            st.markdown("---")
            st.subheader("–ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è")

            try:
                model, mse, rmse, r2, coeffs, feature_names = fit_polynomial_regression(
                    filtered_df, '–ü–ª–æ—â–∞–¥—å', price_column,
                    degree=reg_degree, test_size=reg_test_size
                )

                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("MSE", f"{mse:,.0f}")
                with col2:
                    st.metric("RMSE", f"{rmse:,.0f}")
                with col3:
                    st.metric("R¬≤", f"{r2:.3f}")

                fig2, ax2 = plt.subplots(figsize=(10, 6))

                X_plot = np.linspace(filtered_df['–ü–ª–æ—â–∞–¥—å'].min(), filtered_df['–ü–ª–æ—â–∞–¥—å'].max(), 100).reshape(-1, 1)
                y_plot = model.predict(X_plot)

                ax2.scatter(filtered_df['–ü–ª–æ—â–∞–¥—å'], filtered_df[price_column], alpha=0.6, label='–î–∞–Ω –¥–∞–Ω–Ω—ã–µ–Ω—ã–µ')
                ax2.plot(X_plot, y_plot, color='red', linewidth=2, label=f'–ü–æ–ª–∏–Ω–æ–º {reg_degree} —Å—Ç–µ–ø–µ–Ω–∏')

                ax2.set_xlabel('–ü–ª–æ—â–∞–¥—å (–º¬≤)')
                ax2.set_ylabel('–¶–µ–Ω–∞ –∑–∞ –º¬≤ (—Ä—É–±.)')
                ax2.set_title('–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å —Ü–µ–Ω—ã –æ—Ç –ø–ª–æ—â–∞–¥–∏')
                ax2.legend()
                ax2.grid(True, alpha=0.3)

                st.pyplot(fig2)

            except Exception as e:
                st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—É—é –º–æ–¥–µ–ª—å: {e}")

        if confirm_kp:
            st.markdown("---")
            st.subheader("–ö–æ–º–º–µ—Ä—á–µ—Å–∫–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ")

            manager_name = "–ì—É—Å–µ–≤ –ê–ª–µ–∫—Å–∞–Ω–¥—Ä –°–µ—Ä–≥–µ–µ–≤–∏—á"
            manager_phone = "+7 (977) 123-45-67"

            st.info(f"""
            **–î–∞—Ç–∞:** {datetime.now().strftime('%d.%m.%Y')}

            {f"- –ö–ª–∞—Å—Å –∫–≤–∞—Ä—Ç–∏—Ä—ã: {class_input}" if class_input else ""}
            {f"- –ü–ª–æ—â–∞–¥—å: –æ—Ç {area_min} –¥–æ {area_max} –º¬≤" if area_min > 0 and area_max > 0 else ""}
            {f"- –ö–æ–º–Ω–∞—Ç: {rooms_input}" if rooms_input else ""}
            {f"- –†–∞–π–æ–Ω: {district_input}" if district_input else ""}

            - –ù–∞–π–¥–µ–Ω–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤: {len(filtered_df)}
            - –°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞ –∑–∞ –º¬≤: {class_avg_price:,.0f} —Ä—É–±.
            - –ú–µ–¥–∏–∞–Ω–Ω–∞—è —Ü–µ–Ω–∞: {class_median_price:,.0f} —Ä—É–±.

            - {manager_name}
            - üìû {manager_phone}
            - ‚úâÔ∏è gusev@realestate.ru
            """)

        if export_pptx:
            try:
                pptx_bytes = create_presentation(input_data, filtered_df)
                st.markdown(get_download_link(pptx_bytes, "commercial_offer.pptx", "üìé –°–∫–∞—á–∞—Ç—å –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—é"), unsafe_allow_html=True)
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏: {e}")

st.markdown("---")
st.caption("¬© 2024 –ê–Ω–∞–ª–∏–∑ —Ä—ã–Ω–∫–∞ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ | –ú–µ–Ω–µ–¥–∂–µ—Ä: –ì—É—Å–µ–≤ –ê–ª–µ–∫—Å–∞–Ω–¥—Ä –°–µ—Ä–≥–µ–µ–≤–∏—á +7 (977) 123-45-67")
